{
  "SceneGraphComplementor": {
    "phase_prompt": [
      "You are an AI expert in semantic navigation and scene graph reasoning. ",
      "Task: Complete the scene graph by predicting the missing elements at the unexplored location.",
      "Task description: A robot is navigating a building to find {target} and has observed the following scene graph. What would it see if it visits **location {frontier_location}**?",
      "Observed sceen graph: ",
      "{scene_description}",
      "Think step by step and reason yourself to the right decisions to make sure we get it right.",
      "You will first infer the possible observations using commonsense, ensuring logical consistency with the given observations.",
      "Then you will output the predicted scene graph including original one. The output file must strictly follow the same json format as the input. Including a start flag of \"Start\" and an end flag \"End\", in between is the predicted scene graph:",
      "# Completed scene graph",
      "# Start",
      "```json",
      "```",
      "# End",
      "Please note that the scene graph should be aligned with commonsense.",
      "1. Be compact, DO NOT predict SAME OBJECT TYPE TWICE! ",
      "2. NO MORE THAN 5 predictions.",
      "3. Focus on the most typical ones, do not imagine the rare scenarios!",
      "4. Follow the below format of the example.",
      "Example: ",
      "dict('rooms': [dict('caption': #RoomType, 'id': 'RoomNum', 'center': [x, y], 'regions': [dict('caption': #RegionType, 'id': 'RoomNum.RegionNum', 'center': [x, y], 'objects': [dict('caption': #ObjectType, 'id': 'RoomNum.RegionNum.ObjNum', 'center': [x, y], 'confidence': #ConfScore, 'corr_score': #CorrelationWithTarget)])])])"
    ]
  },
  "HighLevelSceneGraphComplementor": {
    "phase_prompt": [
      "You are an AI expert in semantic navigation and scene graph reasoning. ",
      "Task: Complete the scene graph by predicting the missing elements at the unexplored location.",
      "Task description: A robot is navigating a building to find {target} and has observed the following scene graph. What would it see if it visits the following locations? Return only the confident possible list.",
      "Context: A robot is navigating a building to find {target} and has observed the following scene graph:",
      "Explored regions: ",
      "{scene_description}",
      "The robot is about to explore {frontier_location}.",
      "Predict what it is likely to see based on commonsense reasoning and logical consistency with previous observations.",
      "Guidelines:",
      "1. Infer possible regions (potential choices: 'bedroom', 'living room', 'bathroom', 'kitchen', 'dining room', 'office', 'gym', 'lounge', 'laundry room').",
      "2. Predict typical objects for the inferred region.",
      "3. Ensure logical consistency with prior observations.",
      "4. Avoid redundancy: Do not predict the same object type twice.",
      "Output Format: ",
      "- The scene graph must follow the given JSON structure. ",
      "- Including a start flag of \"Start\" and an end flag \"End\", in between is the predicted scene graph:",
      "# Predicted scene graph",
      "# Start",
      "```json",
      "```",
      "# End",
      "Example: ",
      "dict('regions': [dict('caption': #RegionType, 'center': [x, y], 'objects': [dict('caption': #ObjectType, 'center': [x, y], 'confidence': #ConfScore, 'corr_score': #CorrelationWithTarget)])])])"
    ]
  },
  "GlobalSceneGraphComplementor": {
    "phase_prompt": [
      "You are an AI expert in semantic navigation and scene graph reasoning. ",
      "Task: Predict the missing elements in the scene graph at unexplored locations based on prior observations and commonsense reasoning.",
      "Task description: A robot is navigating a building to find {target} and has observed the following scene graph. ",
      "The goal is to predict what the robot might see when it explores the {frontier_locations}, which are at the boundary of unexplored regions.",
      "Before reaching these frontiers, we aim to infer possible regions and objects based on the typical arrangement of spaces in a building.",
      "Explored regions: ",
      "{scene_description}",
      "Think step by step and reason yourself about the scene at each frontier, and then cross-validate and merge them to a consisteny and reasonbale scene.",
      "Guidelines:",
      "1. Only predict the unknown regions! We trust the observation. DO NOT PREDICT THE OBSERVED REGION!",
      "2. Infer possible regions (potential choices: 'bedroom', 'living room', 'bathroom', 'kitchen', 'dining room', 'office', 'gym', 'lounge', 'laundry room').",
      "3. Predict typical objects for the inferred region.",
      "4. Ensure logical consistency with prior observations and among different frontiers.",
      "5. Avoid redundancy: Do not predict the same object type twice.",
      "Output Format: ",
      "- The scene graph must follow the given JSON structure. ",
      "- Including a start flag of \"Start\" and an end flag \"End\", in between is the predicted scene graph:",
      "# Predicted scene graph",
      "# Start",
      "```json",
      "```",
      "# End",
      "Example: ",
      "dict('regions': [dict('caption': #RegionType, 'center': [x, y], 'objects': [dict('caption': #ObjectType, 'center': [x, y], 'confidence': #ConfScore, 'corr_score': #CorrelationWithTarget)])])])"
    ]
  },
  "GlobalBEVSceneGraphComplementor": {
    "phase_prompt": [
      "You are an AI expert in semantic navigation and scene graph reasoning.",
      "Task description: Your goal is navigating a building to find {target}, using the provided BEV map and scene graph.",
      "",
      "You must predict semantic regions and objects based on prior observations and commonsense spatial layouts.",
      "",
      "Legend:",
      "- Dark gray: obstacles",
      "- White: free space",
      "- Light gray: unknown regions (need prediction)",
      "- Red: current agent location: {agent_location}",
      "- Black: frontier candidate points: {frontier_locations}",
      "",
      "Map coordinates: origin is top-left (0,0). X increases left to right. Y increases top to bottom. Map size: (800,800).",
      "",
      "Prediction Scope:",
      "- For each frontier, predict the **most likely semantic region** it leads into based on prior layout and spatial context.",
      "- Additionally, if the frontier connects to a larger **free visible space**, predict the possible structure and extent of that room beyond the frontier.",
      "- This may involve predicting one or more regions **per frontier**, depending on the connected free space area and layout.",
      "- You should infer room types and include typical objects, using prior building conventions and observed layout.",
      "",
      "Spatial Reasoning Guidelines:",
      "- Bathrooms are near bedrooms.",
      "- Kitchens are usually adjacent to living/dining rooms.",
      "- Living rooms often occupy central, open spaces.",
      "- Bedrooms and offices may be more isolated.",
      "- Avoid unrealistic placement (e.g., kitchen inside a small hallway or next to a gym).",
      "",
      "Global Constraints:",
      "- Predict only in unexplored regions. Do not modify observed areas.",
      "- Ensure spatial and semantic consistency. Avoid duplicate rooms unless plausible (e.g., multiple bedrooms okay).",
      "- Validate each prediction globally â€” do not assign the same region type redundantly unless it fits the layout.",
      "",
      "Prediction Targets:",
      "1. For each frontier, predict:",
      "   - The semantic region it likely connects to.",
      "   - The extended visible free space behind it (if applicable) and the region it forms.",
      "   - Typical objects and their likely positions.",
      "",
      "2. Use commonsense and layout logic to reason about the scene behind the visible free space.",
      "",
      "Output Format:",
      "- Do not modify observed regions.",
      "- Merge your predictions with the observed scene graph.",
      "- The scene graph must follow the given JSON structure. Integrate the prediction and the original observed scene graph as the final output.",
      "- Including a start flag of \"Start\" and an end flag \"End\", in between is the final scene graph:",
      "# Predicted scene graph",
      "# Start",
      "```json",
      "```",
      "# End",
      "Example: ",
      "dict('regions': [dict('caption': #RegionType, 'center': [x, y], 'objects': [dict('caption': #ObjectType, 'center': [x, y], 'confidence': #ConfScore, 'corr_score': #CorrelationWithTarget)])])])"
    ]
  },
  "GlobalBEVSceneGraphPlanner": {
    "phase_prompt": [
      "You are an AI expert in semantic navigation and scene graph reasoning.",
      "Task description: Your goal is navigating a building to find {target} via weighting the possibilities of each frontier using the provided BEV map and scene graph.",
      "",
      "You must make the decision based on prior observations and commonsense spatial layouts.",
      "",
      "Legend:",
      "- Dark gray: obstacles",
      "- White: free space",
      "- Light gray: unknown regions (need prediction)",
      "- Red: current agent location: {agent_location}",
      "- Black: frontier candidate points: {frontier_locations}",
      "",
      "Map coordinates: origin is top-left (0,0). X increases left to right. Y increases top to bottom. Map size: (800,800).",
      "",
      "Reasoning Guidelines:",
      "- 1 For each frontier, we should predict the possibility of the target appearing around based on prior layout and spatial context.",
      "- 2. Use commonsense and layout logic to reason about the scene behind the visible free space.",
      "",
      "Spatial Reasoning Guidelines:",
      "- Bathrooms are near bedrooms.",
      "- Kitchens are usually adjacent to living/dining rooms.",
      "- Living rooms often occupy central, open spaces.",
      "- Bedrooms and offices may be more isolated.",
      "- Avoid unrealistic placement (e.g., kitchen inside a small hallway or next to a gym).",
      "",
      "Output Format:",
      "# Predicted scores",
      "# Start",
      "```json",
      "```",
      "# End",
      "Example: ",
      "[dict('frontier': 1, 'center': [x,y], 'score': s), dict('frontier': 2, 'center': [x,y], 'score': s)]"
    ]
  },
  "GlobalBEVRGBSceneGraphComplementor_Old": {
    "phase_prompt": [
      "You are an AI expert in semantic navigation and scene graph reasoning.",
      "Task description: Your goal is navigating a building to find {target}, using the provided BEV map and scene graph.",
      "",
      "You must predict the semantics (regions or objects) in unknown area around the frontiers based on prior observations and commonsense spatial layouts.",
      "",
      "Legend:",
      "- Black: unknown regions (need prediction)",
      "- Red mark: current agent location: {agent_location}",
      "- White mark: frontier candidate points: {frontier_locations}",
      "",
      "Map coordinates: origin is top-left (0,0). X increases left to right. Y increases top to bottom. Map size: (800,800).",
      "",
      "Prediction Scope:",
      "- For each frontier, predict the **most likely semantic region** it leads into based on prior layout and spatial context.",
      "- Additionally, if the frontier connects to a larger **free visible space**, predict the possible structure and extent of that room beyond the frontier.",
      "- This may involve predicting one or more regions **per frontier**, depending on the connected free space area and layout.",
      "- You should infer room types and include typical objects, using prior building conventions and observed layout.",
      "",
      "Spatial Reasoning Guidelines:",
      "- Bathrooms are near bedrooms.",
      "- Kitchens are usually adjacent to living/dining rooms.",
      "- Living rooms often occupy central, open spaces.",
      "- Bedrooms and offices may be more isolated.",
      "- Avoid unrealistic placement (e.g., kitchen inside a small hallway or next to a gym).",
      "",
      "Global Constraints:",
      "- Predict only in unexplored regions. Do not modify observed areas.",
      "- Ensure spatial and semantic consistency. Avoid duplicate rooms unless plausible (e.g., multiple bedrooms okay).",
      "- Validate each prediction globally â€” do not assign the same region type redundantly unless it fits the layout.",
      "",
      "Prediction Targets:",
      "1. For each frontier, predict:",
      "   - The semantic region it likely connects to.",
      "   - The extended visible free space behind it (if applicable) and the region it forms.",
      "   - Typical objects and their likely positions.",
      "",
      "2. Use commonsense and layout logic to reason about the scene behind the visible free space.",
      "",
      "Output Format:",
      "- Do not modify observed regions.",
      "- Merge your predictions with the observed scene graph.",
      "- The scene graph must follow the given JSON structure. Integrate the prediction and the original observed scene graph as the final output.",
      "- Including a start flag of \"Start\" and an end flag \"End\", in between is the final scene graph:",
      "# Predicted scene graph",
      "# Start",
      "```json",
      "```",
      "# End",
      "Example: ",
      "dict('regions': [dict('caption': #RegionType, 'center': [x, y], 'objects': [dict('caption': #ObjectType, 'center': [x, y], 'confidence': #ConfScore, 'corr_score': #CorrelationWithTarget)])])])"
    ]
  },
  "GlobalBEVRGBSceneGraphComplementor": {
    "phase_prompt": [
      "The following describes the layout of a house:",
      "{scene_description}",
      "The goal is to predict what the robot might see when it explores the {frontier_locations} that can help find {target}, which are at the boundary of unexplored regions.",
      "Potential region choices: 'bedroom', 'living room', 'bathroom', 'kitchen', 'dining room', 'office', 'gym', 'lounge', 'laundry room'.",
      "Output Format:",
      "- Do not modify observed regions.",
      "- Merge your predictions with the observed scene graph.",
      "- The scene graph must follow the given JSON structure. Integrate the prediction and the original observed scene graph as the final output.",
      "- Including a start flag of \"Start\" and an end flag \"End\", in between is the final scene graph:",
      "# Predicted scene graph",
      "# Start",
      "```json",
      "```",
      "# End",
      "Example: ",
      "dict('regions': [dict('caption': #RegionType, 'center': [x, y], 'objects': [dict('caption': #ObjectType, 'center': [x, y], 'confidence': #ConfScore, 'corr_score': #CorrelationWithTarget)])])])"
    ]
  },
  "GlobalBEVRGBSceneGraphComplementor_TopK": {
    "phase_prompt": [
      "The following describes the layout of a house:",
      "{scene_description}",
      "The goal is to predict what the robot might see when it explores the {frontier_locations} that can help find {target}, which are at the boundary of unexplored regions (dark area).",
      "If the frontiers are close to each other, just output a single prediction, do not make duplicate and too dense predictions.",
      "Infer the Top3 most likely captions for the unexplored regions and also the top3 most typical objects within the region.",
      "Potential region choices: 'bedroom', 'living room', 'bathroom', 'kitchen', 'dining room', 'office', 'gym', 'lounge', 'laundry room'.",
      "Output Format:",
      "- Do not modify observed regions.",
      "- The scene graph must follow the given JSON structure.",
      "- Including a start flag of \"Start\" and an end flag \"End\", in between is the final scene graph:",
      "# Predicted scene graph",
      "# Start",
      "```json",
      "```",
      "# End",
      "Example: ",
      "dict('regions': [dict('caption': dict(#RegionType1: #ConfScore1, #RegionType2: #ConfScore2, #RegionType3: #ConfScore3), 'center': [x, y], 'objects': [dict('caption': #ObjectType, 'center': [x, y], 'confidence': #ConfScore, 'corr_score': #CorrelationWithTarget)])])])"
    ]
  },
  "GlobalBEVRGBSceneGraphComplementor_TopK_Number": {
    "phase_prompt": [
      "The following describes the layout of a house:",
      "{scene_description}",
      "The goal is to predict what the robot might see when it explores the unknown regions (dark area) {frontier_locations} that can help find {target}.",
      "Infer the top 3 most likely captions for the unexplored regions and also the top 3 most typical objects within the region.",
      "Potential region choices: 'bedroom', 'living room', 'bathroom', 'kitchen', 'dining room', 'office', 'gym', 'lounge', 'laundry room'.",
      "Output Format:",
      "- Do not modify observed regions.",
      "- The scene graph must follow the given JSON structure.",
      "- Including a start flag of \"Start\" and an end flag \"End\", in between is the final scene graph:",
      "# Predicted scene graph",
      "# Start",
      "```json",
      "```",
      "# End",
      "Example: ",
      "dict('regions': [dict('caption': dict(#RegionType1: #ConfScore1, #RegionType2: #ConfScore2, #RegionType3: #ConfScore3), 'center': [x, y], 'objects': [dict('caption': #ObjectType, 'center': [x, y], 'confidence': #ConfScore, 'corr_score': #CorrelationWithTarget)])])])"
    ]
  },
  "GlobalBEVRGBSceneGraphComplementor_TopK_Number_WithCorrelation": {
    "phase_prompt": [
      "You are given the bird eye view of the house, and the goal is to predict what the robot might see when it explores the unknown regions (dark area) that can help find **{target}**.",
      "For each region, infer top 2 most likely captions with confidence scores (sum of two confidence scores should be 1) and also the top 3 most typical objects within the region.",
      "HINT: Think about the typical layout of a house, here are some examples layout with possibilities:",
      "- kitchen is usually near bathroom (21%), living room (19%), laundry room (19%), study room (15%).",
      "- study room is usually near living room (24%), bathroom (24%), kitchen (17%), hallway (11%).",
      "- dining room is usually near study room (27%), storage (27%), bathroom (27%).",
      "- living room is usually near bathroom (27%), study room (21%), laundry room (14%), kitchen (12%), bedroom (11%).",
      "- bathroom is usually near bedroom (22%), hallway (15%), laundry room (12%), entryway (10%).",
      "- bedroom is usually near bathroom (34%), wardrobe area (16%), hallway (15%), entryway (10%).",
      "- bedroom is usually NOT near study room, kitchen.",
      "- dining room is usually NOT near bedroom.",
      "- study room is usually NOT near bedroom.",
      "- living room is usually NOT near storage, wardrobe area.",
      "**Available region choices**: {region_choices}. Set caption to 'unknown' if you are uncertain or no choice makes sense.",
      "**Unknown regions locations and nearby regions**:",
      "{frontier_locations}",
      "Output Requirements:",
      "- DO NOT include the observed regions above, ONLY predict the unknown regions.",
      "- DO NOT explain your task, just give the short reasoning and the final prediction.",
      "- The scene graph must follow the given JSON structure. REMOVE spaces in the JSON string.",
      "- Including a start flag of \"Start\" and an end flag \"End\", in between is the final scene graph.",
      "- Give a short 20-words-max reasoning for each predicted region.",
      "Output Format:",
      "# Start",
      "```json",
      "```",
      "# End",
      "Example: ",
      "dict('regions': [dict('id': pred_#RegionID, 'caption': dict(#RegionType1: #ConfScore1, #RegionType2: #ConfScore2), 'reasoning': #Reasoning, 'center': [x, y], 'objects': [dict('caption': #ObjectType, 'center': [x, y], 'confidence': #ConfScore, 'corr_score': #CorrelationWithTarget)])])])"
    ]
  },
  "RegionCorrEstimatior": {
    "phase_prompt": [
      "What is the probability of target A appearing near region B. ",
      "[A:{observation}], [B:{target}]. ",
      "Answer with a value from 0 to 1. Answer only the value of probability and do not answer any other text. If you are uncertain, rethink for one more time. And then give the final answer"
    ]
  },
  "RegionCaptionGenerator": {
    "phase_prompt": [
      "Given the objects, analyze their common functionality and infer the most likely intermediate semantic concept (e.g., furniture type, functional area). Consider typical use cases and spatial associations between objects. Only provide the inferred semantic concept as the answer.",
      "Example 1:",
      "Objects: [stove, refrigerator, sink, cutting board]",
      "#Answer: Kitchen",
      "Example 2:",
      "Objects: [sofa, TV, coffee table, bookshelf]",
      "#Answer: Living area",
      "Example 3:",
      "Objects: [bed, nightstand, wardrobe, lamp]",
      "#Answer: Sleeping area",
      "Now, analyze the given objects [{objects}] and infer the most likely semantic concept. (potential choices: 'bedroom', 'living room', 'bathroom', 'kitchen', 'dining room', 'office', 'gym', 'lounge', 'laundry room')",
      "#Answer:"
    ]
  },
  "RegionCaptionGenerator_WithConfidence": {
    "phase_prompt": [
      "Given the objects, analyze their common functionality and infer the most likely intermediate semantic concept (e.g., furniture type, functional area). Consider typical use cases and spatial associations between objects. Only provide the inferred semantic concept as the answer.",
      "Example 1:",
      "Objects: [stove, refrigerator, sink, cutting board]",
      "#Answer: Kitchen",
      "Example 2:",
      "Objects: [sofa, TV, coffee table, bookshelf]",
      "#Answer: Living area",
      "Example 3:",
      "Objects: [bed, nightstand, wardrobe, lamp]",
      "#Answer: Sleeping area",
      "Now, analyze the given objects and its detection confidence [{objects}] and infer the most likely semantic concept. (potential choices: 'bedroom', 'living room', 'bathroom', 'kitchen', 'dining room', 'office', 'gym', 'lounge', 'laundry room')",
      "Note that the confidence score is between 0 and 1, and the higher the score, the more confident the detection. Rely more on the objects with higher confidence, as the low score may be FPs.",
      "#Answer:"
    ]
  },
  "RegionCaptionGenerator_Global": {
    "phase_prompt": [
      "Given the objects, analyze their common functionality and infer the most likely intermediate semantic concept (e.g., furniture type, functional area). Consider typical use cases and spatial associations between objects.",
      "Example 1:",
      "Objects: [stove, refrigerator, sink, cutting board]",
      "Region: Kitchen",
      "Example 2:",
      "Objects: [sofa, TV, coffee table, bookshelf]",
      "Region: Living area",
      "Example 3:",
      "Objects: [bed, nightstand, wardrobe, lamp]",
      "Region: Sleeping area",
      "Now, analyze the following regions with its contained objects [{objects}] and infer the most likely semantic concept for each region. (potential choices: 'bedroom', 'living room', 'bathroom', 'kitchen', 'dining room', 'office', 'gym', 'lounge', 'laundry room')",
      "Note that consider these regions are coming from the same indoor environmeny, when doing the analysing, consider global consistency and the typical floorplan in indoor arangement.",
      "Output Format: follow the given JSON structure.",
      "- Including a start flag of \"Start\" and an end flag \"End\", in between is the final scene graph:",
      "# Predicted region caption",
      "# Start",
      "```json",
      "```",
      "# End",
      "Example: ",
      "[dict('idx': #idx, 'caption': #RegionType,...]"
    ]
  },
  "RegionCaptionGenerator_TopK": {
    "phase_prompt": [
      "Given the objects, analyze their common functionality and infer the most likely intermediate semantic concept (e.g., furniture type, functional area). Consider typical use cases and spatial associations between objects.",
      "Example 1:",
      "Objects: [stove, refrigerator, sink, cutting board]",
      "Region: Kitchen",
      "Example 2:",
      "Objects: [sofa, TV, coffee table, bookshelf]",
      "Region: Living area",
      "Example 3:",
      "Objects: [bed, nightstand, wardrobe, lamp]",
      "Region: Sleeping area",
      "Now, analyze the following regions with its contained objects [{objects}] and infer the Top3 most likely semantic concept for each region. (potential choices: 'bedroom', 'living room', 'bathroom', 'kitchen', 'dining room', 'office', 'gym', 'lounge', 'laundry room')",
      "Note that consider these regions are coming from the same indoor environmeny, when doing the analysing, consider global consistency and the typical floorplan in indoor arangement.",
      "Output Format: follow the given JSON structure.",
      "- Including a start flag of \"Start\" and an end flag \"End\", in between is the final scene graph:",
      "# Predicted region caption",
      "# Start",
      "```json",
      "```",
      "# End",
      "Example: ",
      "[dict('idx': #idx, 'caption': dict(#RegionType1: #ConfScore1, #RegionType2: #ConfScore2),...]"
    ]
  }
}