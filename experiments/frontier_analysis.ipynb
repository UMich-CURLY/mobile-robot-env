{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# db: simple read test\n",
    "import json\n",
    "import yaml\n",
    "import types\n",
    "import open_clip\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "from scipy.spatial import KDTree\n",
    "from icecream import ic\n",
    "import time\n",
    "\n",
    "from utils.db_utils import get_df, get_data, connect_db, DB\n",
    "from utils.plotly_utils import *\n",
    "from utils.vis import *\n",
    "from utils.predict_scenegraph import PredictSceneGraph\n",
    "from utils.imagine_nav_planner import ImagineNavPlanner\n",
    "from utils.scene_graph_utils import update_region\n",
    "from utils.scene_graph_utils import detect_match\n",
    "from experiments.test_scenegraph_offline import eval_scenegraph\n",
    "from constants import *\n",
    "\n",
    "dump_folder = './dump/prediction_may13/'\n",
    "output_folder = f'{dump_folder}/objectnav-dino'\n",
    "\n",
    "# list db size\n",
    "! ls -lh $output_folder\n",
    "\n",
    "# load results\n",
    "results = get_df(f'{output_folder}/result.db', 'result')\n",
    "print(f'Loaded {len(results)} results')\n",
    "print(f'Current success rate: {results.tail(1)[\"success\"].values[0]/len(results):.2%}')\n",
    "print(f'Current SPL: {results[\"spl\"].mean():.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access db\n",
    "import os\n",
    "import pathlib\n",
    "with DB(f'{output_folder}/result.db') as con:\n",
    "    table = con.table('result')\n",
    "    print(table)\n",
    "# episode infos\n",
    "# steps_df = get_df(f'{output_folder}/result.db', 'result', select=['count_steps', 'episode', 'target', 'habitat_success', 'switch_upstair_count', 'switch_downstair_count'])\n",
    "steps_df = get_df(f'{output_folder}/result.db', 'result', filter=lambda x:x['count_steps']>490, select=['count_steps', 'episode', 'target', 'habitat_success', 'switch_upstair_count', 'switch_downstair_count'])\n",
    "print(steps_df.head(30))\n",
    "# step infos\n",
    "sample_episode_label = steps_df['episode'].values[0]\n",
    "with DB(f'{output_folder}/steps/{sample_episode_label}.db') as con:\n",
    "    table = con.table('step_data')\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load agent modules\n",
    "device = torch.device(\"cuda\")\n",
    "args = types.SimpleNamespace(**json.load(open(f'{dump_folder}/args.json')))\n",
    "with open(f'{dump_folder}/{args.exp_config}') as f:\n",
    "    exp_config = yaml.safe_load(f)\n",
    "clip_model, _, clip_preprocess = open_clip.create_model_and_transforms(\n",
    "    \"ViT-H-14\", \"laion2b_s32b_b79k\"\n",
    ")\n",
    "clip_model = clip_model.to(device).half()\n",
    "clip_tokenizer = open_clip.get_tokenizer(\"ViT-H-14\")\n",
    "clip_model_list = (clip_model, clip_preprocess, clip_tokenizer)\n",
    "exp_config['utility']['object_correlation'] = 'llm'\n",
    "exp_config['utility']['region_correlation'] = 'text'\n",
    "\n",
    "imagine_nav_planner = ImagineNavPlanner(args, exp_config, clip_model_list)\n",
    "scene_graph = imagine_nav_planner.scene_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sg_data(episode_label, step=None):\n",
    "    if step is None:\n",
    "        filter = lambda x: (x['episode_label']==episode_label)\n",
    "    else:\n",
    "        filter = lambda x: (x['episode_label']==episode_label) & (x['step']==step)\n",
    "    try:\n",
    "        data = get_data(\n",
    "            f'{output_folder}/steps/{episode_label}.db',\n",
    "            'step_data',\n",
    "            filter=filter,\n",
    "            select=[\n",
    "                'global_scene_graph_pickle',\n",
    "                'gt_scenegraph',\n",
    "                'timestamp',\n",
    "                'step',\n",
    "                'cate_object',\n",
    "                'origins_grid',\n",
    "                'current_grid_pose',\n",
    "                'camera_position_tensor',\n",
    "                #### \n",
    "                # 'global_bev_rgb_map_tensor',\n",
    "                # 'annotated_image_tensor',\n",
    "                # 'gradient_map_tensor',\n",
    "                # 'color_image_tensor',\n",
    "                # 'object_nodes_pickle',\n",
    "            ]\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "    # data = data[np.argmax([x['timestamp'] for x in data])]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test clip reigon\n",
    "\n",
    "from collections import Counter\n",
    "# get an image for a region\n",
    "def update_image_idx(self, region):\n",
    "    objects = region['objects']\n",
    "    image_coverage = Counter()\n",
    "    for obj in objects:\n",
    "        for i,idx in enumerate(obj['image_idx']):\n",
    "            image_coverage[idx] += obj['conf'][i]\n",
    "    region['image_idx'] = image_coverage.most_common(1)[0][0]\n",
    "\n",
    "def get_region_vis_feat(self, region, image_history, topk=1):\n",
    "    objects = region['objects']\n",
    "    unique_obj_count = {}\n",
    "    for obj in objects:\n",
    "        for i, idx in enumerate(obj['image_idx']):\n",
    "            unique_obj_count.setdefault(idx, {})\n",
    "            unique_obj_count[idx].setdefault(obj['caption'], []).append(obj['conf'][i])\n",
    "    image_coverage = Counter()\n",
    "    for idx in unique_obj_count:\n",
    "        for obj, confs in unique_obj_count[idx].items():\n",
    "            image_coverage[idx] += max(confs)\n",
    "    region['image_coverage'] = image_coverage\n",
    "    region['unique_obj_count'] = unique_obj_count\n",
    "    vis_feat = None\n",
    "    coverage_sum = 0\n",
    "    for image_idx, coverage in image_coverage.most_common(topk):\n",
    "        image = image_history[image_idx]\n",
    "        if vis_feat is None:\n",
    "            vis_feat = coverage*self.get_vis_feat(image)\n",
    "        else:\n",
    "            vis_feat += self.get_vis_feat(image)\n",
    "        coverage_sum += coverage\n",
    "    vis_feat /= coverage_sum\n",
    "    region['idx_list'] = list(image_coverage.keys())\n",
    "    region['coverages'] = list(image_coverage.values())\n",
    "    return vis_feat\n",
    "\n",
    "def generate_region_caption_TopK_clip(self, scene_graph, image_history, topk=3, img_topk=3):\n",
    "    for room in scene_graph['rooms']:\n",
    "        for region in room['regions']:\n",
    "            similarities = []\n",
    "            vis_feat = get_region_vis_feat(self, region, image_history, topk=img_topk)\n",
    "            for caption in region_captions:\n",
    "                similarities.append(self.get_vis_sim_score(vis_feat, caption))\n",
    "            captions = sorted(zip(similarities, region_captions), key=lambda x: x[0], reverse=True)[:topk]\n",
    "            region['caption'] = {}\n",
    "            region['clip_feat'] = vis_feat\n",
    "            for similarity, caption in captions:\n",
    "                region['caption'][caption] = similarity\n",
    "            region['corr_score'] = self.get_vis_sim_score(vis_feat, self.target)\n",
    "    return scene_graph\n",
    "\n",
    "episode_label = steps_df['episode'].iloc[3]\n",
    "data = get_sg_data(episode_label)\n",
    "\n",
    "step = data[490]\n",
    "image_history = [x['color_image'] for x in data]\n",
    "grid_size = args.map_resolution\n",
    "origins_grid = step['origins_grid']\n",
    "bev_map = step['global_bev_rgb_map']\n",
    "obs_sg = step['global_scene_graph']\n",
    "\n",
    "scene_graph.set_target(step['cate_object'])\n",
    "scene_graph.scene_graph = obs_sg\n",
    "\n",
    "gt_sg = step['gt_scenegraph']\n",
    "obs_regions = [update_region(region, grid_size, origins_grid) for room in obs_sg['rooms'] for region in room['regions']]\n",
    "gt_regions = [update_region(region, grid_size, origins_grid) for room in gt_sg['floors'] for region in room['regions']]\n",
    "obs_objects = [obj for room in obs_sg['rooms'] for region in room['regions'] for obj in region['objects']   ]\n",
    "gt_objects = [obj for room in gt_sg['floors'] for region in room['regions'] for obj in region['objects']]\n",
    "start_time = time.time()  \n",
    "obs_sg = generate_region_caption_TopK_clip(scene_graph, obs_sg, image_history)\n",
    "print(f'Time taken for region caption: {time.time() - start_time}')\n",
    "\n",
    "# match region to gt\n",
    "# matches, metric = eval_scenegraph(clip_model_list, obs_regions, gt_regions, obs_objects, gt_objects)\n",
    "# for match in matches['region_precision_relaxed']:\n",
    "#     match['q']['gt_caption'] = match['k']['caption']\n",
    "\n",
    "# calculate region precision relaxed\n",
    "matches, score = detect_match(\n",
    "    clip_model_list=clip_model_list,\n",
    "    keys=gt_regions,\n",
    "    queries=obs_regions,\n",
    "    knn=3,\n",
    "    overlap_relaxed=True,\n",
    "    corr_score=None,\n",
    "    topk=2\n",
    ")\n",
    "for match in matches:\n",
    "    match['q']['gt_caption'] = match['k']['caption']\n",
    "print(f'region precision relaxed: {score}')\n",
    "\n",
    "# calculate region recall relaxed\n",
    "region_recall_relaxed_matches, region_recall_relaxed = detect_match(\n",
    "    clip_model_list=clip_model_list,\n",
    "    keys=obs_regions,\n",
    "    queries=gt_regions,\n",
    "    knn=3,\n",
    "    overlap_relaxed=True,\n",
    "    corr_score=None,\n",
    "    topk=2\n",
    ")\n",
    "print(f'region recall relaxed: {score}')\n",
    "\n",
    "\n",
    "ic(step['cate_object'])\n",
    "ic(len(obs_regions))\n",
    "# ic(obs_regions[10])\n",
    "for region in obs_regions:\n",
    "    print(f'region {region[\"id\"]}: images= {list(zip(region[\"idx_list\"], region[\"coverages\"]))}')\n",
    "    print(f'caption: {region[\"caption\"]}')\n",
    "    print(f'gt_caption: {region[\"gt_caption\"]}')\n",
    "    # print(region['image_coverage'])\n",
    "    # print(region['unique_obj_count'])\n",
    "    # for obj in region['objects']:\n",
    "    #     print(obj['id'], obj['caption'], obj['image_idx'])\n",
    "    print('--------------------------------')\n",
    "# ic(step['object_nodes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([obj for room in obs_sg['rooms'] for region in room['regions'] for obj in region['objects']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_id = 26\n",
    "frame_id = obs_regions[region_id]['idx_list'][0]\n",
    "show_image(data[frame_id]['annotated_image'][...,::-1])\n",
    "show_image(data[frame_id]['color_image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_corr(vis_feat, target):\n",
    "    return imagine_nav_planner.scene_graph.get_vis_sim_score(vis_feat, target)\n",
    "# vis_feat = imagine_nav_planner.scene_graph.get_vis_feat(data[frame_id]['color_image'])\n",
    "vis_feat = imagine_nav_planner.scene_graph.get_vis_feat(cv2.imread('img/image.png')[...,::-1])\n",
    "# vis_feat = get_region_vis_feat(scene_graph, obs_regions[region_id], image_history, topk=1)\n",
    "\n",
    "# imagine_nav_planner.scene_graph.get_vis_sim_score(vis_feat, step['cate_object'])\n",
    "# target_list = categories_21_plus_stairs#+['somewhere near '+x for x in categories_21_plus_stairs]\n",
    "# target_list = ['stairs', 'not stairs', 'somewhere near stairs', 'somewhere not near stairs']\n",
    "target_list = region_captions\n",
    "# target_list = detector_classes\n",
    "score_list = []\n",
    "for target in target_list:\n",
    "    score_list.append(get_image_corr(vis_feat, target))\n",
    "top5_result = sorted(zip(score_list, target_list), key=lambda x: x[0], reverse=True)[:5]\n",
    "# print top 5 with score and target\n",
    "ic(top5_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test text sim range\n",
    "# print(scene_graph.get_text_sim_score('guest bedroom', 'bed'))\n",
    "# print(scene_graph.get_text_sim_score('guest bedroom', 'toilet'))\n",
    "# print(scene_graph.get_text_sim_score('guest bedroom', 'tv_monitor'))\n",
    "# print(scene_graph.get_text_sim_score('guest bedroom', 'sofa'))\n",
    "# print(scene_graph.get_text_sim_score('guest bedroom', 'chair'))\n",
    "# print(scene_graph.get_text_sim_score('guest bedroom', 'plant'))\n",
    "\n",
    "# print(scene_graph.get_text_sim_score('bed', 'bed'))\n",
    "# print(scene_graph.get_text_sim_score('bed', 'toilet'))\n",
    "# print(scene_graph.get_text_sim_score('bed', 'tv_monitor'))\n",
    "# print(scene_graph.get_text_sim_score('bed', 'sofa'))\n",
    "# print(scene_graph.get_text_sim_score('bed', 'chair'))\n",
    "# print(scene_graph.get_text_sim_score('bed', 'plant'))\n",
    "\n",
    "\n",
    "print(scene_graph.get_text_sim_score('living room', 'sofa'))\n",
    "print(scene_graph.get_text_sim_score('living room', 'stairs'))\n",
    "print(scene_graph.get_text_sim_score('living room', 'tv_monitor'))\n",
    "print(scene_graph.get_text_sim_score('bedroom', 'toilet'))\n",
    "\n",
    "print(scene_graph.get_text_sim_score('stair hall', 'stairs'))\n",
    "print(scene_graph.get_text_sim_score('study room', 'stairs'))\n",
    "print(scene_graph.get_text_sim_score('living room', 'stairs'))\n",
    "print(scene_graph.get_text_sim_score('kitchen', 'stairs'))\n",
    "print(scene_graph.get_text_sim_score('hallway', 'stairs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_regions[region_id]['caption']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_id = np.argmax([obs_regions[region_id]['caption'][caption] for caption in ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = create_fig(img=bev_map[...,::-1])\n",
    "plot_region(fig, obs_regions, 480, show_objects=True)\n",
    "fig.show()\n",
    "\n",
    "fig = create_fig(img=bev_map[...,::-1])\n",
    "plot_region(fig, gt_regions, 480, show_objects=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print all region captions\n",
    "gt_region_captions = set()\n",
    "for i in range(len(results)):\n",
    "    episode_label = results['episode'].iloc[i]\n",
    "    print(f'Processing episode {episode_label}')\n",
    "    data = get_sg_data(episode_label)\n",
    "    if data is None:\n",
    "        print(f'No data for episode {episode_label}')\n",
    "        continue\n",
    "    count_episode += 1\n",
    "    grid_size = args.map_resolution\n",
    "    step = data[-1]\n",
    "    origins_grid = step['origins_grid']\n",
    "    gt_sg = step['gt_scenegraph']\n",
    "    gt_regions = [update_region(region, grid_size, origins_grid) for room in gt_sg['floors'] for region in room['regions']]\n",
    "    for room in gt_sg['floors']:\n",
    "        for region in room['regions']:\n",
    "            gt_region_captions.add(region['caption'])\n",
    "\n",
    "gt_region_captions_map = {}\n",
    "region_captions = set()\n",
    "for region_caption in gt_region_captions:\n",
    "    merged_region_caption = region_caption\n",
    "    if 'bath' in region_caption or 'shower' in region_caption or 'wash' in region_caption:\n",
    "        merged_region_caption = 'bathroom'\n",
    "    elif 'powder' in region_caption or 'nursery' in region_caption or 'spa' in region_caption:\n",
    "        merged_region_caption = 'bathroom'\n",
    "    elif 'bedroom' in region_caption:\n",
    "        merged_region_caption = 'bedroom'\n",
    "    elif 'hallway' in region_caption:\n",
    "        merged_region_caption = 'hallway'\n",
    "    elif 'study' in region_caption:\n",
    "        merged_region_caption = 'study room'\n",
    "    elif 'laundry' in region_caption:\n",
    "        merged_region_caption = 'laundry room'\n",
    "    elif 'lounge' in region_caption:\n",
    "        merged_region_caption = 'living room'\n",
    "    elif 'kitchen' in region_caption:\n",
    "        merged_region_caption = 'kitchen'\n",
    "    elif 'dining' in region_caption:\n",
    "        merged_region_caption = 'dining room'\n",
    "    elif 'guest' in region_caption:\n",
    "        merged_region_caption = 'bedroom'\n",
    "    elif 'office' in region_caption:\n",
    "        merged_region_caption = 'study room'\n",
    "    elif 'pantry' in region_caption:\n",
    "        merged_region_caption = 'storage'\n",
    "    elif 'shower' in region_caption:\n",
    "        merged_region_caption = 'bathroom'\n",
    "    elif 'storage' in region_caption:\n",
    "        merged_region_caption = 'storage'\n",
    "    elif 'music' in region_caption or 'media' in region_caption or 'rec' in region_caption or 'entertainment' in region_caption:\n",
    "        merged_region_caption = 'study room'\n",
    "    elif 'stair' in region_caption:\n",
    "        merged_region_caption = 'stair hall'\n",
    "    elif 'family' in region_caption:\n",
    "        merged_region_caption = 'living room'\n",
    "    elif 'utility' in region_caption:\n",
    "        merged_region_caption = 'storage'\n",
    "    elif 'closet' in region_caption:\n",
    "        merged_region_caption = 'wardrobe area'\n",
    "    elif 'toilet' in region_caption:\n",
    "        merged_region_caption = 'bathroom'\n",
    "    elif 'corridor' in region_caption:\n",
    "        merged_region_caption = 'hallway'\n",
    "    elif 'attic access' in region_caption:\n",
    "        merged_region_caption = 'stair hall'\n",
    "    region_captions.add(merged_region_caption)\n",
    "    gt_region_captions_map[region_caption] = merged_region_caption\n",
    "print(region_captions)\n",
    "ic(gt_region_captions_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gt co-occurrence (obj-obj, region-obj)\n",
    "from collections import Counter\n",
    "\n",
    "def get_sg_data(episode_label, step=None):\n",
    "    if step is None:\n",
    "        filter = lambda x: (x['episode_label']==episode_label) & (x['step']%5==0)\n",
    "    else:\n",
    "        filter = lambda x: (x['episode_label']==episode_label)\n",
    "    try:\n",
    "        data = get_data(\n",
    "            f'{output_folder}/steps/{episode_label}.db',\n",
    "            'step_data',\n",
    "            filter=filter,\n",
    "            select=[\n",
    "                'global_scene_graph_pickle',\n",
    "                'gt_scenegraph',\n",
    "                'timestamp',\n",
    "                'step',\n",
    "                'cate_object',\n",
    "                'origins_grid',\n",
    "                'current_grid_pose',\n",
    "                'camera_position_tensor',\n",
    "                #### \n",
    "                # 'global_bev_rgb_map_tensor',\n",
    "                # 'annotated_image_tensor',\n",
    "                # 'gradient_map_tensor',\n",
    "                # 'color_image_tensor',\n",
    "                # 'object_nodes_pickle',\n",
    "            ]\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "    # data = data[np.argmax([x['timestamp'] for x in data])]\n",
    "    return data\n",
    "\n",
    "\n",
    "obj_to_obj_co_occurrence = {}\n",
    "region_to_obj_co_occurrence = {}\n",
    "count_episode = 0\n",
    "# for i in range(1):\n",
    "for i in range(len(results)):\n",
    "    episode_label = results['episode'].iloc[i]\n",
    "    print(f'Processing episode {episode_label}')\n",
    "    data = get_sg_data(episode_label)\n",
    "    if data is None:\n",
    "        print(f'No data for episode {episode_label}')\n",
    "        continue\n",
    "    count_episode += 1\n",
    "    grid_size = args.map_resolution\n",
    "    step = data[-1]\n",
    "    origins_grid = step['origins_grid']\n",
    "    gt_sg = step['gt_scenegraph']\n",
    "    gt_regions = [update_region(region, grid_size, origins_grid) for room in gt_sg['floors'] for region in room['regions']]\n",
    "    for region in gt_regions:\n",
    "        object_counter = Counter()\n",
    "        for obj in region['objects']:\n",
    "            object_counter[obj['caption']] += 1\n",
    "        for obj, count in object_counter.items():\n",
    "            region_caption = gt_region_captions_map[region['caption']]\n",
    "            region_to_obj_co_occurrence.setdefault(region_caption, {})\n",
    "            region_to_obj_co_occurrence[region_caption].setdefault(obj, 0)\n",
    "            region_to_obj_co_occurrence[region_caption][obj] += count\n",
    "        for i, (obj, count) in enumerate(object_counter.items()):\n",
    "            obj_to_obj_co_occurrence.setdefault(obj, {})\n",
    "            # increase the count for every other object in the region\n",
    "            for j, (other_obj, other_count) in enumerate(object_counter.items()):\n",
    "                if i != j:\n",
    "                    obj_to_obj_co_occurrence[obj].setdefault(other_obj, 0)\n",
    "                    obj_to_obj_co_occurrence[obj][other_obj] += count\n",
    "print(f'Processed {count_episode} episodes')\n",
    "ic(obj_to_obj_co_occurrence)\n",
    "ic(region_to_obj_co_occurrence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_near_region_co_occurrence = {}\n",
    "near_region_knn = 3\n",
    "near_region_radius = 60\n",
    "count_episode = 0\n",
    "for i in range(len(results)):\n",
    "    episode_label = results['episode'].iloc[i]\n",
    "    print(f'Processing episode {episode_label}')\n",
    "    data = get_sg_data(episode_label)\n",
    "    if data is None:\n",
    "        print(f'No data for episode {episode_label}')\n",
    "        continue\n",
    "    count_episode += 1\n",
    "    grid_size = args.map_resolution\n",
    "    step = data[-1]\n",
    "    origins_grid = step['origins_grid']\n",
    "    gt_sg = step['gt_scenegraph']\n",
    "    gt_regions = [update_region(region, grid_size, origins_grid) for room in gt_sg['floors'] for region in room['regions']]\n",
    "    tree = KDTree([region['center'] for region in gt_regions])\n",
    "    for region in gt_regions:\n",
    "        distances, indices = tree.query([region['center']], k=near_region_knn+1)\n",
    "        if not isinstance(distances, np.ndarray):\n",
    "            distances, indices = np.array([distances]), np.array([indices])\n",
    "        for distance, index in zip(distances[0], indices[0]):\n",
    "            near_region = gt_regions[index]\n",
    "            if region['id']==near_region['id']:\n",
    "                continue\n",
    "            if distance<near_region_radius:\n",
    "                region_caption = gt_region_captions_map[region['caption']]\n",
    "                near_region_caption = gt_region_captions_map[near_region['caption']]\n",
    "                region_near_region_co_occurrence.setdefault(region_caption, {})\n",
    "                region_near_region_co_occurrence[region_caption].setdefault(near_region_caption, 0)\n",
    "                region_near_region_co_occurrence[region_caption][near_region_caption] += 1\n",
    "\n",
    "print(f'Processed {count_episode} episodes')\n",
    "ic(region_near_region_co_occurrence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save co-occurrence\n",
    "np.save('tools/obj_co_occurrence.npy', obj_to_obj_co_occurrence)\n",
    "np.save('tools/region_co_occurrence.npy', region_to_obj_co_occurrence)\n",
    "np.save('tools/region_region_co_occurrence.npy', region_near_region_co_occurrence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils.plotly_utils import *\n",
    "from constants import *\n",
    "obj_to_obj_co_occurrence = np.load('tools/obj_co_occurrence.npy', allow_pickle=True).tolist()\n",
    "region_to_obj_co_occurrence = np.load('tools/region_co_occurrence.npy', allow_pickle=True).tolist()\n",
    "region_near_region_co_occurrence = np.load('tools/region_region_co_occurrence.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot co-occurrence\n",
    "n_obj = len(categories_21_plus_stairs)\n",
    "n_region = len(region_captions)\n",
    "heatmap_obj_obj = np.zeros((n_obj, n_obj))\n",
    "for obj_i in obj_to_obj_co_occurrence:\n",
    "    for obj_j in obj_to_obj_co_occurrence[obj_i]:\n",
    "        heatmap_obj_obj[obj_category_to_idx[obj_i], obj_category_to_idx[obj_j]] = obj_to_obj_co_occurrence[obj_i][obj_j]\n",
    "\n",
    "heatmap_region_obj = np.zeros((n_region, n_obj))\n",
    "for region_i in region_to_obj_co_occurrence:\n",
    "    if region_i=='UNKNOWN':\n",
    "        continue\n",
    "    for obj_j in region_to_obj_co_occurrence[region_i]:\n",
    "        heatmap_region_obj[region_caption_to_idx[region_i], obj_category_to_idx[obj_j]] = region_to_obj_co_occurrence[region_i][obj_j]\n",
    "n_obj_detector = len(detector_classes)\n",
    "\n",
    "heatmap_region_region = np.zeros((n_region, n_region))\n",
    "for region_i in region_near_region_co_occurrence:\n",
    "    for region_j in region_near_region_co_occurrence[region_i]:\n",
    "        if region_i=='UNKNOWN' or region_i==region_j:\n",
    "            continue\n",
    "        heatmap_region_region[region_caption_to_idx[region_i], region_caption_to_idx[region_j]] = region_near_region_co_occurrence[region_i][region_j]\n",
    "\n",
    "# normalize\n",
    "heatmap_obj_obj_norm = heatmap_obj_obj.copy().clip(max=764)\n",
    "heatmap_obj_obj_norm -= heatmap_obj_obj_norm.min()\n",
    "heatmap_obj_obj_norm /= heatmap_obj_obj_norm.max()\n",
    "heatmap_obj_obj_norm = heatmap_obj_obj_norm*0.8+0.2\n",
    "heatmap_region_obj_norm = heatmap_region_obj.copy().clip(max=266)\n",
    "heatmap_region_obj_norm -= heatmap_region_obj_norm.min()\n",
    "heatmap_region_obj_norm /= heatmap_region_obj_norm.max()\n",
    "heatmap_region_obj_norm = heatmap_region_obj_norm*0.8+0.2\n",
    "# print(heatmap_obj_obj_norm.max(), heatmap_obj_obj_norm.min())\n",
    "# print(heatmap_region_obj_norm.max(), heatmap_region_obj_norm.min())\n",
    "\n",
    "\n",
    "# plot scores\n",
    "fig = create_fig(600, 600)\n",
    "plot_heatmap(fig, heatmap_obj_obj_norm, 'obj-obj co-occurrence', x=categories_21_plus_stairs, y=categories_21_plus_stairs)\n",
    "fig.show()\n",
    "fig = create_fig(600, 600)\n",
    "plot_heatmap(fig, heatmap_region_obj_norm, 'region-obj co-occurrence', x=categories_21_plus_stairs, y=gt_region_captions)\n",
    "fig.show()\n",
    "fig = create_fig(600, 600)\n",
    "plot_heatmap(fig, heatmap_region_region, 'region-region co-occurrence', x=gt_region_captions, y=gt_region_captions)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_region_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_target = len(category_to_id)\n",
    "n_obj = len(categories_21_plus_stairs)\n",
    "heatmap_obj_target = np.zeros((n_obj, n_target))\n",
    "for i, obj in enumerate(categories_21_plus_stairs):\n",
    "    for j, target in enumerate(category_to_id):\n",
    "        heatmap_obj_target[i, j] = heatmap_obj_obj_norm[categories_21_plus_stairs.index(obj), categories_21_plus_stairs.index(target)]\n",
    "\n",
    "heatmap_region_target = np.zeros((n_region, n_target))\n",
    "for i, region in enumerate(region_captions):\n",
    "    for j, target in enumerate(category_to_id):\n",
    "        heatmap_region_target[i, j] = heatmap_region_obj_norm[region_captions.index(region), categories_21_plus_stairs.index(target)]\n",
    "\n",
    "\n",
    "# plot co-occurrence\n",
    "fig = create_fig(600, 600)\n",
    "plot_heatmap(fig, heatmap_obj_target, 'obj-obj co-occurrence', x=category_to_id, y=categories_21_plus_stairs)\n",
    "fig.show()\n",
    "fig = create_fig(600, 600)\n",
    "plot_heatmap(fig, heatmap_region_target, 'region-obj co-occurrence', x=category_to_id, y=gt_region_captions)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chance_regions = ['bathroom', 'kitchen', 'bedroom', 'dining room', 'living room', 'study room']\n",
    "heatmap_region_important = np.zeros((n_region, len(chance_regions)))\n",
    "for i, region in enumerate(region_captions):\n",
    "    for j, chance_region in enumerate(chance_regions):\n",
    "        heatmap_region_important[i, j] = heatmap_region_region[region_captions.index(region), region_captions.index(chance_region)]\n",
    "\n",
    "heatmap_region_possibility = heatmap_region_important/heatmap_region_important.sum(axis=0)\n",
    "fig = create_fig(600, 600)\n",
    "plot_heatmap(fig, np.where((heatmap_region_important>5) & (heatmap_region_possibility>0.1), heatmap_region_possibility, 0), 'region-region co-occurrence', x=chance_regions, y=gt_region_captions)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import peek\n",
    "hint_pairs = {}\n",
    "hint_list = []\n",
    "# get i,j index of heatmap_region_important>15\n",
    "high_freq_mask = (heatmap_region_important>5) & (heatmap_region_possibility>0.1)\n",
    "for i, j in zip(*np.where(high_freq_mask)):\n",
    "    pair = (chance_regions[j], gt_region_captions[i])\n",
    "    possibility = heatmap_region_possibility[i, j]\n",
    "    hint_pairs.setdefault(pair[0], []).append((pair[1], possibility))\n",
    "for k,v in hint_pairs.items():\n",
    "    v.sort(key=lambda x: x[1], reverse=True)\n",
    "    hint_pairs[k] = v[:4]\n",
    "    near_regions = \", \".join([f'{x[0]} ({x[1]*100:.0f}%)' for x in v])\n",
    "    hint_list.append(f'- {k} is usually near {near_regions}.')\n",
    "# print hints\n",
    "print(',\\n'.join([f'\"{x}\"' for x in hint_list]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import peek\n",
    "hint_pairs = {}\n",
    "hint_list = []\n",
    "# get i,j index of heatmap_region_important>15\n",
    "low_freq_mask = (heatmap_region_important<5) & (heatmap_region_important>0)\n",
    "for i, j in zip(*np.where(low_freq_mask)):\n",
    "    pair = (chance_regions[j], gt_region_captions[i])\n",
    "    possibility = heatmap_region_possibility[i, j]\n",
    "    hint_pairs.setdefault(pair[0], []).append((pair[1], possibility))\n",
    "for k,v in hint_pairs.items():\n",
    "    v.sort(key=lambda x: x[1], reverse=True)\n",
    "    hint_pairs[k] = v[:4]\n",
    "    near_regions = \", \".join([f'{x[0]}' for x in v])\n",
    "    hint_list.append(f'- {k} is usually NOT near {near_regions}.')\n",
    "# print hints\n",
    "print(',\\n'.join([f'\"{x}\"' for x in hint_list]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('tools/heatmap_obj_obj.npy', heatmap_obj_obj_norm)\n",
    "np.save('tools/heatmap_region_obj.npy', heatmap_region_obj_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_obj_obj = np.load('tools/heatmap_obj_obj.npy', allow_pickle=True)\n",
    "heatmap_region_obj = np.load('tools/heatmap_region_obj.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cooccurrence_object(obj_label, target_label):\n",
    "    if obj_label == target_label:\n",
    "        return 1\n",
    "    elif obj_label in categories_21_plus_stairs and target_label in categories_21_plus_stairs:\n",
    "        return heatmap_obj_obj[categories_21_plus_stairs.index(obj_label), categories_21_plus_stairs.index(target_label)]\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def get_cooccurrence_region(region_label, target_label):\n",
    "    if region_label in region_captions and target_label in categories_21_plus_stairs:\n",
    "        return heatmap_region_obj[region_captions.index(region_label), categories_21_plus_stairs.index(target_label)]\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "print(get_cooccurrence_object('bed', 'toilet'))\n",
    "print(get_cooccurrence_object('bed', 'sofa'))\n",
    "print(get_cooccurrence_object('bed', 'bed'))\n",
    "print(get_cooccurrence_region('bedroom', 'sofa'))\n",
    "print(get_cooccurrence_region('bathroom', 'sofa'))\n",
    "print(get_cooccurrence_region('living room', 'sofa'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_to_obj_co_occurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_to_obj_co_occurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# co_occur_mtx = np.load('tools/obj.npy')\n",
    "# co_occur_mtx -= co_occur_mtx.min()\n",
    "# co_occur_mtx /= co_occur_mtx.max() \n",
    "\n",
    "# co_occur_room_mtx = np.load('tools/room.npy')\n",
    "# co_occur_room_mtx -= co_occur_room_mtx.min()\n",
    "# co_occur_room_mtx /= co_occur_room_mtx.max()\n",
    "\n",
    "# fig = create_fig(600, 600)\n",
    "# plot_heatmap(fig, co_occur_mtx, 'llm obj-obj co-occurrence', x=categories_21_plus_stairs, y=categories_21_plus_stairs)\n",
    "# fig.show()\n",
    "# fig = create_fig(600, 600)\n",
    "# plot_heatmap(fig, co_occur_room_mtx, 'llm region-obj co-occurrence', x=categories_21_plus_stairs, y=gt_region_captions)\n",
    "# fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all gt region captions\n",
    "gt_region_captions = set()\n",
    "\n",
    "for i in range(len(results)):\n",
    "    episode_label = results['episode'].iloc[i]\n",
    "    data = get_sg_data(episode_label)\n",
    "    if data is None:\n",
    "        print(f'No data for episode {episode_label}')\n",
    "        continue\n",
    "    grid_size = args.map_resolution\n",
    "    origins_grid = step['origins_grid']\n",
    "    gt_sg = step['gt_scenegraph']\n",
    "    gt_regions = [update_region(region, grid_size, origins_grid) for room in gt_sg['floors'] for region in room['regions']]\n",
    "    for region in gt_regions:\n",
    "        gt_region_captions.add(region['caption'])\n",
    "gt_region_captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gt co-occurrence (obj-obj, region-obj)\n",
    "from collections import Counter\n",
    "\n",
    "def get_sg_data(episode_label, step=None):\n",
    "    if step is None:\n",
    "        filter = lambda x: (x['episode_label']==episode_label) & (x['step']%5==0)\n",
    "    else:\n",
    "        filter = lambda x: (x['episode_label']==episode_label)\n",
    "    try:\n",
    "        data = get_data(\n",
    "            f'{output_folder}/steps/{episode_label}.db',\n",
    "            'step_data',\n",
    "            filter=filter,\n",
    "            select=[\n",
    "                'global_scene_graph_pickle',\n",
    "                'gt_scenegraph',\n",
    "                'timestamp',\n",
    "                'step',\n",
    "                'cate_object',\n",
    "                'origins_grid',\n",
    "                'current_grid_pose',\n",
    "                'camera_position_tensor',\n",
    "                'frontier_scores_pickle'\n",
    "            ]\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "    # data = data[np.argmax([x['timestamp'] for x in data])]\n",
    "    return data\n",
    "\n",
    "\n",
    "count_episode = 0\n",
    "frontier_scores = {'baseline': [], 'exploration': [], 'exploitation': [], 'distance': [], 'final': []}\n",
    "for i in range(len(results)):\n",
    "    episode_label = results['episode'].iloc[i]\n",
    "    # print(f'Processing episode {episode_label}')\n",
    "    data = get_sg_data(episode_label)\n",
    "    if data is None:\n",
    "        print(f'No data for episode {episode_label}')\n",
    "        continue\n",
    "    count_episode += 1\n",
    "    for step in data:\n",
    "        if not 'frontier_scores' in step:\n",
    "            continue\n",
    "        for key in step['frontier_scores']:\n",
    "            frontier_scores[key].extend(step['frontier_scores'][key])\n",
    "print(f'Processed {count_episode} episodes')\n",
    "for key in frontier_scores:\n",
    "    print(key, np.mean(frontier_scores[key]), np.min(frontier_scores[key]), np.max(frontier_scores[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum non-zero\n",
    "scores = np.array(frontier_scores['exploitation'])\n",
    "np.min(scores[scores>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vln",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
