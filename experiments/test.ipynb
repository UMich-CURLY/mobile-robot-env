{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42023698",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.applyColorMap(\n",
    "    np.arange(246, dtype=np.uint8), cv2.COLORMAP_JET\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdacd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.vis import remove_image_border\n",
    "\n",
    "img = np.zeros((100, 100), dtype=np.uint8)\n",
    "img[50:70, 50:70] = 150\n",
    "bg = 0\n",
    "# _, img = cv2.threshold(img, 250, 5, cv2.THRESH_BINARY)\n",
    "_, img = cv2.threshold(img, 5, 255, cv2.THRESH_BINARY_INV)\n",
    "coords = cv2.findNonZero(255-img)\n",
    "x, y, w, h = cv2.boundingRect(coords)\n",
    "print(x, y, w, h)\n",
    "img = cv2.rectangle(img, (x, y), (x+w, y+h), 200, 5)\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becaaa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "scenes = [*range(20)]\n",
    "args = type('', (), {})()\n",
    "args.num_processes = 3\n",
    "\n",
    "n_gpu = torch.cuda.device_count()\n",
    "args.num_processes *= n_gpu\n",
    "\n",
    "scene_split_sizes = [int(np.floor(len(scenes) / args.num_processes))\n",
    "                        for _ in range(args.num_processes)]\n",
    "for i in range(len(scenes) % args.num_processes):\n",
    "    scene_split_sizes[i] += 1\n",
    "print(scene_split_sizes)\n",
    "\n",
    "\n",
    "args.num_processes = int(args.num_processes/n_gpu)\n",
    "for gpu_id in range(n_gpu):\n",
    "    for i in range(args.num_processes):\n",
    "        print(gpu_id, sum(scene_split_sizes[:i*n_gpu+gpu_id+1])-sum(scene_split_sizes[:i*n_gpu+gpu_id]))\n",
    "    # proc_config = config_env.clone()\n",
    "    # proc_config.defrost()\n",
    "    # proc_config.DATASET.SPLIT = args.split\n",
    "\n",
    "    # if len(scenes) > 0:\n",
    "    #     proc_config.DATASET.CONTENT_SCENES = scenes[\n",
    "    #         sum(scene_split_sizes[:i]):\n",
    "    #         sum(scene_split_sizes[:i + 1])\n",
    "    #     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519ffd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from supervision.draw.color import Color, ColorPalette\n",
    "ColorPalette.DEFAULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3a73ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "loc = torch.stack([torch.rand(100), torch.rand(100)]).T\n",
    "loc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83134df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 5cdEh9F2hJL\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "def get_scene_id(scene_path):\n",
    "    # Get the scene_id from the path\n",
    "    scene_id = scene_path.split(\"/\")[-1]\n",
    "    scene_id = re.sub(r'\\.basis\\.glb$', '', scene_id)\n",
    "    return scene_id\n",
    "\n",
    "scene_path ='data/scene_datasets/hm3d/val/00853-5cdEh9F2hJL/5cdEh9F2hJL.basis.glb'\n",
    "scene_id = get_scene_id(scene_path)\n",
    "print(scene_id)\n",
    "scenes = ['4ok3usBNeis', '5cdEh9F2hJL', '6s7QHgap2fW', 'DYehNKdT76V', 'Dd4bFSTQ8gi', 'Nfvxx8J5NCo', 'QaLdnwvtxbs', 'TEEsavR23oF', 'XB4GS9ShBRE', 'bxsVRursffK', 'cvZr5TUy5C5', 'mL8ThkuaVTM', 'mv2HUxq3B53', 'p53SfW6mjZe', 'q3zU7Yy5E5s', 'qyAac8rV8Zk', 'svBbv1Pavdk', 'wcojb4TFT35', 'ziup5kvtCCR', 'zt1RVoi7PcG']\n",
    "print(scene_id in scenes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfda0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "        object_captions = '. '.join(categories_21) +'.'\n",
    "        self.classes = copy.deepcopy(object_captions).strip('.').split('. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7982c626",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "log_dir = '/root/Projects/VLN-Game/dump/logs/objectnav-dino/'\n",
    "\n",
    "per_episode_error = []\n",
    "# read all_info.log\n",
    "if os.path.exists(log_dir + \"all_info.log\"):\n",
    "    with open(log_dir + \"all_info.log\", 'r') as fp:\n",
    "        lines = fp.readlines()\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if line != \"\":\n",
    "                per_episode_error.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fa4283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find TEEsavR23oF_57 in per_episode_error[i]['episode] in one line\n",
    "episode_done_list = [x['episode'] for x in per_episode_error]\n",
    "'TEEsavR23oF_57' in episode_done_list, 'TEEsavR23oF_123' in episode_done_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41526956",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from constants import color_palette, category_to_id #, category_to_id_replica\n",
    "\n",
    "color_pal = [int(x * 255.) for x in color_palette]\n",
    "sem_map = np.zeros((480, 480), dtype=np.uint8)\n",
    "sem_map_vis = Image.new(\"P\", (sem_map.shape[1],\n",
    "                                sem_map.shape[0]))\n",
    "sem_map_vis.putpalette(color_pal)\n",
    "sem_map_vis.putdata(sem_map.flatten().astype(np.uint8))\n",
    "sem_map_vis = sem_map_vis.convert(\"RGB\")\n",
    "sem_map_vis = np.flipud(sem_map_vis)\n",
    "\n",
    "sem_map_vis = sem_map_vis[:, :, [2, 1, 0]]\n",
    "vis_image = cv2.resize(sem_map_vis, (480, 480),\n",
    "                            interpolation=cv2.INTER_NEAREST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608ab75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "per_episode_error = []\n",
    "# read all_info.log\n",
    "log_dir = '/root/Projects/VLN-Game/dump/logs/objectnav-dino/'\n",
    "if os.path.exists(log_dir + \"all_info.log\"):\n",
    "    with open(log_dir + \"all_info.log\", 'r') as fp:\n",
    "        lines = fp.readlines()\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if line != \"\":\n",
    "                per_episode_error.append(json.loads(line))\n",
    "spl = [x['spl'] for x in per_episode_error]\n",
    "print(np.mean(spl))\n",
    "steps = steps = [x['count_steps'] for x in per_episode_error]\n",
    "print(np.mean(steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4912d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a02a0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=99\n",
    "0<=x<100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfba2a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test2(callback):\n",
    "    callback()\n",
    "\n",
    "def test1():\n",
    "    aa = 1\n",
    "    print('3:', aa)\n",
    "    def test3():\n",
    "        test3.aa = 100\n",
    "        aa += 1\n",
    "        print('2:', aa)\n",
    "    test2(test3)\n",
    "test1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c689c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OLLAMA_HOST\"] = \"http://localhost:11500\"\n",
    "from ollama import chat\n",
    "\n",
    "# from pathlib import Path\n",
    "\n",
    "# Pass in the path to the image\n",
    "# path = input('Please enter the path to the image: ')\n",
    "\n",
    "# You can also pass in base64 encoded image data\n",
    "# img = base64.b64encode(Path(path).read_bytes()).decode()\n",
    "# or the raw bytes\n",
    "# img = Path(path).read_bytes()\n",
    "\n",
    "response = chat(\n",
    "  model='llama3.2-vision',\n",
    "  messages=[\n",
    "    {\n",
    "      'role': 'user',\n",
    "      'content': 'What is in this image? Be concise.',\n",
    "      'images': ['/root/Projects/VLN/img/framework.png'],\n",
    "    }\n",
    "  ],\n",
    ")\n",
    "\n",
    "print(response.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d6d4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import time\n",
    "import ollama\n",
    "from multiprocessing import Process, Queue, Event\n",
    "def run_ollama_serve(port, gpu_id):\n",
    "    os.environ[\"OLLAMA_HOST\"] = f'http://127.0.0.1:{port}'\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)\n",
    "    ollama_process = subprocess.Popen(\n",
    "        [\"ollama\", \"serve\"],\n",
    "        bufsize=-1,\n",
    "        env=os.environ,\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.STDOUT,\n",
    "    )\n",
    "    def read_output(process, status):\n",
    "        while True:\n",
    "            output = process.stdout.readline()\n",
    "            if b\"Listening\" in output:\n",
    "                print(\"[OLLAMA] ollama serve started successfully\")\n",
    "                status.put(1)\n",
    "            elif b\"Error\" in output:\n",
    "                print(\"[OLLAMA] \", output.decode().strip())\n",
    "                status.put(0)\n",
    "    status = Queue()\n",
    "    Process(target=read_output, args=(ollama_process, status), daemon=True).start()\n",
    "    try:\n",
    "        if not status.get(True, timeout=3):\n",
    "            raise Exception(\"[OLLAMA] Error starting ollama serve\")\n",
    "    except Exception as e:\n",
    "        print(\"[OLLAMA] Timeout waiting for ollama serve to start\")\n",
    "        raise\n",
    "    return ollama_process\n",
    "\n",
    "port = 11600\n",
    "print(f\"Starting ollama serve on port {port}...\")\n",
    "ollama_process = run_ollama_serve(port, 2)\n",
    "print(\"querying...\")\n",
    "client = ollama.Client(\n",
    "    host=f'http://localhost:{port}'\n",
    ")\n",
    "print(\"chat...\")\n",
    "response = client.chat(\n",
    "  model='llama3.2-vision',\n",
    "  messages=[\n",
    "    {\n",
    "      'role': 'user',\n",
    "      'content': 'What is LLM? Be concise.',\n",
    "    #   'images': ['/root/Projects/VLN/img/framework.png'],\n",
    "    }\n",
    "  ],\n",
    ")\n",
    "print(\"done...\")\n",
    "\n",
    "print(response.message.content)\n",
    "\n",
    "# Kill the process\n",
    "print(\"Killing ollama serve process...\")\n",
    "ollama_process.terminate()\n",
    "print(\"Process terminated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d868d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_process.stdout.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e7f48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.inf>5, np.inf>np.inf, np.inf>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681401cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test():\n",
    "    def test(self):\n",
    "        if hasattr(self, '_test'):\n",
    "            print('yes!')\n",
    "        else:\n",
    "            print('no!')\n",
    "        self._test = 1\n",
    "\n",
    "t = Test()\n",
    "t.test()\n",
    "t.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49541a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.environ[\"OLLAMA_HOST\"] = \"http://localhost:11500\"\n",
    "from ollama import chat\n",
    "import cv2\n",
    "import base64\n",
    "\n",
    "# from pathlib import Path\n",
    "\n",
    "# Pass in the path to the image\n",
    "# path = input('Please enter the path to the image: ')\n",
    "\n",
    "# You can also pass in base64 encoded image data\n",
    "# img = base64.b64encode(Path(path).read_bytes()).decode()\n",
    "# or the raw bytes\n",
    "# img = Path('/root/Projects/VLN/img/framework.png').read_bytes()\n",
    "img = cv2.imread('/root/Projects/VLN/img/framework.png')\n",
    "\n",
    "retval, buffer = cv2.imencode('.png', img)\n",
    "img_base64 = base64.b64encode(buffer).decode('utf-8')\n",
    "response = chat(\n",
    "  model='llama3.2-vision',\n",
    "  messages=[\n",
    "    {\n",
    "      'role': 'user',\n",
    "      'content': 'What is in this image? Be concise.',\n",
    "      'images': [img_base64],\n",
    "    }\n",
    "  ],\n",
    ")\n",
    "\n",
    "print(response.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593092d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if img is None or img.size == 0:\n",
    "    print(\"Image is empty or failed to load\")\n",
    "else:\n",
    "    print(f\"Image loaded successfully with shape: {img.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205015ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def remove_white_border(vis_image: np.ndarray, padding: int = 10) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Remove white border from the image.\n",
    "    \"\"\"\n",
    "    image_h, image_w = vis_image.shape[:2]\n",
    "    gray = cv2.cvtColor(vis_image, cv2.COLOR_BGR2GRAY)\n",
    "    _, binary = cv2.threshold(gray, 250, 255, cv2.THRESH_BINARY)\n",
    "    coords = cv2.findNonZero(255 - binary)\n",
    "    if coords is not None:\n",
    "        x, y, w, h = cv2.boundingRect(coords)\n",
    "        x += w//2\n",
    "        y += h//2\n",
    "        # fit the ratio of the original image\n",
    "        ratio = image_w / image_h\n",
    "        if w / h > ratio:\n",
    "            h = int(w / ratio)\n",
    "        else:\n",
    "            w = int(h * ratio)\n",
    "        x = int(x - w / 2)\n",
    "        y = int(y - h / 2)\n",
    "        # Add a small padding\n",
    "        x = max(0, x - padding)\n",
    "        y = max(0, y - padding)\n",
    "        w = min(image_w - x, w + 2*padding)\n",
    "        h = min(image_h - y, h + 2*padding)\n",
    "        vis_image = vis_image[y:y+h, x:x+w]\n",
    "        # Resize back to original dimensions\n",
    "        vis_image = cv2.resize(vis_image, (image_w, image_h), interpolation=cv2.INTER_AREA)\n",
    "    return vis_image\n",
    "\n",
    "img1 = np.ones((640, 480, 3), dtype=np.uint8) * 255\n",
    "w,h = 150, 400\n",
    "img1[100:100+h, 100:100+w] = np.random.randint(0, 255, (h, w, 3))\n",
    "img2 = remove_white_border(img1)\n",
    "plt.imshow(img1)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "plt.imshow(img2)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5436576",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.plotly_utils import *\n",
    "\n",
    "distances = np.arange(0, 15, 0.1)\n",
    "min_distance = 0.75\n",
    "close_distance = 3.0\n",
    "min_mask = distances < min_distance\n",
    "close_mask = (distances <= close_distance) & (distances >= min_distance)\n",
    "far_mask = distances > close_distance\n",
    "distance_score = distances.copy()\n",
    "distance_score[min_mask] = distances[min_mask] / min_distance\n",
    "distance_score[close_mask] = 1.0\n",
    "distance_score[far_mask] = 1.0 - (distances[far_mask] - close_distance).clip(max=10)/10.\n",
    "\n",
    "# plot\n",
    "fig = create_fig(300,300)\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=distances,\n",
    "        y=distance_score,\n",
    "        mode='lines',\n",
    "        name='Distance Score',\n",
    "        line=dict(color='blue', width=2),\n",
    "        marker=dict(size=5)\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24070076",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vln",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
