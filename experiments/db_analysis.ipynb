{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caa97e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 51K\n",
      "drwxrwxrwx 44 root root   45 May  5 05:00 episodes\n",
      "drwxrwxrwx  2 root root   32 May  5 04:59 episodes_video\n",
      "drwxrwxrwx  2 root root    4 May  4 22:13 logs\n",
      "-rwxrwxrwx  1 root root  35K May  4 21:54 monitor.html\n",
      "-rw-r--r--  1 root root 780K May  5 05:00 result.db\n"
     ]
    }
   ],
   "source": [
    "# db: simple read test\n",
    "from utils.db_utils import get_df, get_data, connect_db, DB, insert_data, generate_schema\n",
    "\n",
    "dump_folder = '/root/Projects/SG-VLN-axi/dump/5_04_hm3d_baseline_axi'\n",
    "# dump_folder = './dump/baseline_apr20_sample400'\n",
    "output_folder = f'{dump_folder}/objectnav-dino'\n",
    "\n",
    "# list db size\n",
    "! ls -lh $output_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3340445f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from utils.db_utils import get_df, get_data, connect_db, DB, insert_data, generate_schema\n",
    "with DB(f'/root/Projects/SG-VLN-axi/dump/5_04_hm3d_baseline_axi/objectnav-dino/result.db') as con:\n",
    "    data = {'aaa': 1, 'bbb': 2}\n",
    "    schema = generate_schema(data)\n",
    "    con.create_table('step_data', schema=schema, overwrite=True)\n",
    "    table = con.table('step_data')\n",
    "    print('column ',table.columns)\n",
    "    con.raw_sql(\"SET checkpoint_threshold = '100G';\")\n",
    "    con.raw_sql(\"BEGIN TRANSACTION;\")\n",
    "    insert_data(con, 'step_data', data)\n",
    "    con.raw_sql(\"COMMIT;\")\n",
    "    con.raw_sql(\"CHECKPOINT;\")\n",
    "    con.raw_sql(\"BEGIN TRANSACTION;\")\n",
    "    data = {'aaa': 1, 'ccc': '123'}\n",
    "    insert_data(con, 'step_data', data)\n",
    "    data = {'aaa': 123, 'ddd': 2}\n",
    "    insert_data(con, 'step_data', data)\n",
    "    con.raw_sql(\"COMMIT;\")\n",
    "    con.raw_sql(\"CHECKPOINT;\")\n",
    "    print(con.table('step_data').columns)\n",
    "print(get_data(f'/root/Projects/SG-VLN-axi/dump/5_04_hm3d_baseline_axi/objectnav-dino/result.db', 'step_data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cceca4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29c828c",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b71868b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 30 results\n",
      "Current success rate: 76.67%\n",
      "Current SPL: 0.35\n"
     ]
    }
   ],
   "source": [
    "# load results\n",
    "results = get_df(f'{output_folder}/result.db', 'result')\n",
    "print(f'Loaded {len(results)} results')\n",
    "print(f'Current success rate: {results.tail(1)[\"success\"].values[0]/len(results):.2%}')\n",
    "print(f'Current SPL: {results[\"spl\"].mean():.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbda7642",
   "metadata": {},
   "outputs": [
    {
     "ename": "IOException",
     "evalue": "IO Error: Cannot open database \"/root/Projects/SG-VLN-axi/dump/5_04_hm3d_baseline_axi/objectnav-dino/step_data.db\" in read-only mode: database does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOException\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# episode infos\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m steps_df \u001b[38;5;241m=\u001b[39m \u001b[43mget_df\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43moutput_folder\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/step_data.db\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstep_data\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstep\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtimestamp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprocess_label\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepisode_label\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m steps_df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepisode_label\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39magg({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m})\n",
      "File \u001b[0;32m/workspace/Projects/SG-VLN-axi/utils/db_utils.py:107\u001b[0m, in \u001b[0;36mget_df\u001b[0;34m(db_path, table_name, filter, select)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_df\u001b[39m(db_path, table_name, \u001b[38;5;28mfilter\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, select\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 107\u001b[0m     con \u001b[38;5;241m=\u001b[39m \u001b[43mconnect_db\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdb_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretry_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    109\u001b[0m         table \u001b[38;5;241m=\u001b[39m con\u001b[38;5;241m.\u001b[39mtable(table_name)\n",
      "File \u001b[0;32m/workspace/Projects/SG-VLN-axi/utils/db_utils.py:234\u001b[0m, in \u001b[0;36mconnect_db\u001b[0;34m(path, timeout, read_only, retry_interval, database)\u001b[0m\n\u001b[1;32m    232\u001b[0m     con \u001b[38;5;241m=\u001b[39m ibis\u001b[38;5;241m.\u001b[39msqlite\u001b[38;5;241m.\u001b[39mconnect(path)\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m database \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mduckdb\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 234\u001b[0m     con \u001b[38;5;241m=\u001b[39m \u001b[43mibis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mduckdb://\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpath\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_only\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m     con\u001b[38;5;241m.\u001b[39mraw_sql(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSET enable_progress_bar=false\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m database \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpostgres\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/conda/envs/vln/lib/python3.10/site-packages/ibis/backends/__init__.py:1638\u001b[0m, in \u001b[0;36mconnect\u001b[0;34m(resource, **kwargs)\u001b[0m\n\u001b[1;32m   1635\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m   1636\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDon\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt know how to connect to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresource\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1638\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparsed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/conda/envs/vln/lib/python3.10/site-packages/ibis/backends/__init__.py:1671\u001b[0m, in \u001b[0;36mUrlFromPath._from_url\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m   1668\u001b[0m     database \u001b[38;5;241m=\u001b[39m database\u001b[38;5;241m.\u001b[39mabsolute()\n\u001b[1;32m   1670\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_kwargs(kwargs)\n\u001b[0;32m-> 1671\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatabase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/conda/envs/vln/lib/python3.10/site-packages/ibis/backends/__init__.py:928\u001b[0m, in \u001b[0;36mBaseBackend.connect\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    904\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Connect to the database.\u001b[39;00m\n\u001b[1;32m    905\u001b[0m \n\u001b[1;32m    906\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    925\u001b[0m \n\u001b[1;32m    926\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    927\u001b[0m new_backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 928\u001b[0m \u001b[43mnew_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_backend\n",
      "File \u001b[0;32m~/conda/envs/vln/lib/python3.10/site-packages/ibis/backends/__init__.py:943\u001b[0m, in \u001b[0;36mBaseBackend.reconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    941\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Reconnect to the database already configured with connect.\"\"\"\u001b[39;00m\n\u001b[1;32m    942\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_can_reconnect:\n\u001b[0;32m--> 943\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_con_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_con_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    945\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mIbisError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot reconnect to unconfigured \u001b[39m\u001b[38;5;132;01m{self.name}\u001b[39;00m\u001b[38;5;124m backend\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/conda/envs/vln/lib/python3.10/site-packages/ibis/backends/duckdb/__init__.py:406\u001b[0m, in \u001b[0;36mBackend.do_connect\u001b[0;34m(self, database, read_only, extensions, **config)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(database, Path) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m database\u001b[38;5;241m.\u001b[39mstartswith(\n\u001b[1;32m    403\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmd:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmotherduck:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:memory:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    404\u001b[0m ):\n\u001b[1;32m    405\u001b[0m     database \u001b[38;5;241m=\u001b[39m Path(database)\u001b[38;5;241m.\u001b[39mabsolute()\n\u001b[0;32m--> 406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcon \u001b[38;5;241m=\u001b[39m \u001b[43mduckdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_only\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post_connect(extensions)\n",
      "\u001b[0;31mIOException\u001b[0m: IO Error: Cannot open database \"/root/Projects/SG-VLN-axi/dump/5_04_hm3d_baseline_axi/objectnav-dino/step_data.db\" in read-only mode: database does not exist"
     ]
    }
   ],
   "source": [
    "# episode infos\n",
    "steps_df = get_df(f'{output_folder}/step_data.db', 'step_data', select=['step', 'timestamp', 'process_label', 'episode_label'])\n",
    "steps_df.groupby('episode_label').agg({'step': 'max', 'timestamp': 'max'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5490d73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# access db\n",
    "with DB(f'{output_folder}/step_data.db') as con:\n",
    "    table = con.table('step_data')\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e112cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "TableNotFound",
     "evalue": "step_data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCatalogException\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m~/conda/envs/vln/lib/python3.10/site-packages/ibis/backends/duckdb/__init__.py:301\u001b[0m, in \u001b[0;36mBackend.get_schema\u001b[0;34m(self, table_name, catalog, database)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 301\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcon\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m duckdb\u001b[38;5;241m.\u001b[39mCatalogException:\n",
      "\u001b[0;31mCatalogException\u001b[0m: Catalog Error: Table with name step_data does not exist!\nDid you mean \"sqlite_master\"?",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTableNotFound\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# episode infos\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m steps \u001b[38;5;241m=\u001b[39m \u001b[43mget_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43moutput_folder\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/result.db\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstep_data\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstep\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepisode_label\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcvZr5TUy5C5_25\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mselect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstep\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtimestamp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprocess_label\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mglobal_scene_graph\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mglobal_bev_rgb_map\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mglobal_bev_rgb_map_shape\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i,step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(steps):\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i,step[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m/workspace/Projects/SG-VLN-axi/utils/db_utils.py:122\u001b[0m, in \u001b[0;36mget_data\u001b[0;34m(db_path, table_name, filter, select)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_data\u001b[39m(db_path, table_name, \u001b[38;5;28mfilter\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, select\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 122\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mget_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdb_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m     new_data_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(df)):\n",
      "File \u001b[0;32m/workspace/Projects/SG-VLN-axi/utils/db_utils.py:109\u001b[0m, in \u001b[0;36mget_df\u001b[0;34m(db_path, table_name, filter, select)\u001b[0m\n\u001b[1;32m    107\u001b[0m con \u001b[38;5;241m=\u001b[39m connect_db(db_path, read_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, retry_interval\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 109\u001b[0m     table \u001b[38;5;241m=\u001b[39m \u001b[43mcon\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    111\u001b[0m         table \u001b[38;5;241m=\u001b[39m table\u001b[38;5;241m.\u001b[39mfilter(\u001b[38;5;28mfilter\u001b[39m(_))\n",
      "File \u001b[0;32m~/conda/envs/vln/lib/python3.10/site-packages/ibis/backends/duckdb/__init__.py:259\u001b[0m, in \u001b[0;36mBackend.table\u001b[0;34m(self, name, database)\u001b[0m\n\u001b[1;32m    256\u001b[0m catalog \u001b[38;5;241m=\u001b[39m table_loc\u001b[38;5;241m.\u001b[39mcatalog \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    257\u001b[0m database \u001b[38;5;241m=\u001b[39m table_loc\u001b[38;5;241m.\u001b[39mdb \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 259\u001b[0m table_schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatalog\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatalog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatabase\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;66;03m# load geospatial only if geo columns\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m table_schema\u001b[38;5;241m.\u001b[39mgeospatial:\n",
      "File \u001b[0;32m~/conda/envs/vln/lib/python3.10/site-packages/ibis/backends/duckdb/__init__.py:303\u001b[0m, in \u001b[0;36mBackend.get_schema\u001b[0;34m(self, table_name, catalog, database)\u001b[0m\n\u001b[1;32m    301\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcon\u001b[38;5;241m.\u001b[39msql(query)\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m duckdb\u001b[38;5;241m.\u001b[39mCatalogException:\n\u001b[0;32m--> 303\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mTableNotFound(table_name)\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    305\u001b[0m     meta \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mfetch_arrow_table()\n",
      "\u001b[0;31mTableNotFound\u001b[0m: step_data"
     ]
    }
   ],
   "source": [
    "# episode infos\n",
    "steps = get_data(\n",
    "    f'{output_folder}/step_data.db',\n",
    "    'step_data',\n",
    "    filter=lambda x: (x['step']%5==0) & (x['episode_label']=='cvZr5TUy5C5_25'),\n",
    "    select=['step', 'timestamp', 'process_label', 'global_scene_graph', 'global_bev_rgb_map', 'global_bev_rgb_map_shape']\n",
    ")\n",
    "for i,step in enumerate(steps):\n",
    "    print(i,step['step'])\n",
    "print(steps[0]['global_scene_graph'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83664b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(steps[3]['global_bev_rgb_map'].shape)\n",
    "plt.imshow(steps[13]['global_bev_rgb_map'][...,::-1]/255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118730c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# episode infos\n",
    "steps_df = get_df(\n",
    "    f'{output_folder}/step_data.db',\n",
    "    'step_data',\n",
    "    filter=lambda x: (x['step']==35) & (x['episode_label']=='6s7QHgap2fW_89'),\n",
    "    select=['step', 'timestamp', 'episode_label', 'objects_pickle']\n",
    ")\n",
    "steps_df\n",
    "objects = pickle.loads(steps_df['objects_pickle'].values[0])\n",
    "objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c725a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe8022b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: see why these fails\n",
    "# results = get_df(f'{output_folder}/result.db', 'result', filter=lambda x: (x['habitat_success']==0) & (x['distance_to_goal']<0.2))\n",
    "results = get_df(f'{output_folder}/result.db', 'result')\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6764e931",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "dump_folder = './dump/offline_analysis_sample100_apr23_copy/'\n",
    "output_folder = f'{dump_folder}/objectnav-dino'\n",
    "con = duckdb.connect(f'{output_folder}/step_data.db')\n",
    "\n",
    "# data = con.execute(\"PRAGMA table_info('step_data')\").fetchall()\n",
    "# for row in data:\n",
    "#     print(row)\n",
    "\n",
    "data = con.execute(\"PRAGMA storage_info('step_data')\").fetchall()\n",
    "column_size = {}\n",
    "table_size = 0\n",
    "for row in data:\n",
    "    # print(row)\n",
    "    row_group_id = row[0]\n",
    "    column_name = row[1]\n",
    "    start = row[6]\n",
    "    count = row[7]\n",
    "    compression = row[8]\n",
    "    if column_name not in column_size:\n",
    "        column_size[column_name] = 0\n",
    "    column_size[column_name] += count\n",
    "    table_size += count\n",
    "    print(f\"row_group_id: {row_group_id}, Column: {column_name}, Start: {start}, Count: {count}, Compression: {compression}\")\n",
    "# for column_name, count in column_size.items():\n",
    "#     print(f\"Column: {column_name}, Count: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8caabb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, step in enumerate(steps):\n",
    "    if step['global_scene_graph']:\n",
    "        print(index, step['step'], step['time'], step['process_label'], step['episode_label'])\n",
    "        print(step['global_scene_graph'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8840a867",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('episode_label').size().reset_index(name='count')\n",
    "\n",
    "test = con.table('test')\n",
    "print(test.select(['step', 'success', 'info', 'time']).head(10).execute())\n",
    "print('max score:', test[\"info\"][\"score\"].unwrap_as(\"float32\").max().execute())\n",
    "print('mean score:', test[\"info\"][\"score\"].unwrap_as(\"float32\").mean().execute())\n",
    "print('mean step:', test[\"step\"].max().execute())\n",
    "print('success rate:', test[\"success\"].mean().execute())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0fd092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test insert (with db utils)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import ibis\n",
    "import ibis.selectors as s\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "from utils.db_utils import *\n",
    "ibis.options.interactive = True\n",
    "output_path = 'dump/scene_graph_testing/objectnav-dino'\n",
    "db_path = f'{output_path}/test_insert.db'\n",
    "os.remove(db_path) if os.path.exists(db_path) else None\n",
    "\n",
    "with DB(db_path) as con:\n",
    "    data = {'test': np.random.rand(1024*1024), 'label': 123}\n",
    "    schema = generate_schema(data)\n",
    "    print(schema)\n",
    "    con.create_table('test', schema=schema, overwrite=True)\n",
    "    total_start_time = time.time()\n",
    "    con.raw_sql(\"BEGIN TRANSACTION;\")\n",
    "    for i in range(100):\n",
    "        start_time = time.time()\n",
    "        insert_data(con, 'test', data)\n",
    "        print(f'insert time: {time.time()-start_time:.2f}s')\n",
    "    con.raw_sql(\"COMMIT;\")\n",
    "    print(f'total time: {time.time()-total_start_time:.2f}s')\n",
    "    end_time = time.time()\n",
    "print(f'insert time: {time.time()-end_time:.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c554bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test insert/commit/checkpoint with multiple dbs\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import ibis\n",
    "import ibis.selectors as s\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from utils.db_utils import *\n",
    "ibis.options.interactive = True\n",
    "output_path = 'dump/scene_graph_testing/objectnav-dino'\n",
    "db_path = f'{output_path}/test_insert.db'\n",
    "os.remove(db_path) if os.path.exists(db_path) else None\n",
    "\n",
    "def generate_data():\n",
    "    data = {'test': np.random.rand(1024,1024), 'label': 123}\n",
    "    return data\n",
    "\n",
    "# for k in range(3):\n",
    "k=0\n",
    "print(f'writing to {db_path}.{k}')\n",
    "with DB(db_path+f'.{k}') as con:\n",
    "    # con.raw_sql(\"PRAGMA disabled_compression_methods = 'alp,rle';\")\n",
    "    # con.raw_sql(\"PRAGMA force_compression = 'bitpacking';\")\n",
    "    data = generate_data()\n",
    "    print(len(data['test'])/1024/1024)\n",
    "\n",
    "    schema = generate_schema(data)\n",
    "    print(schema)\n",
    "    con.raw_sql(\"SET checkpoint_threshold = '100G';\")\n",
    "    con.create_table('test'+f'_{k}', schema=schema, overwrite=True)\n",
    "    total_start_time = time.time()\n",
    "    for j in range(3):\n",
    "        for i in range(3):\n",
    "            con.raw_sql(\"BEGIN TRANSACTION;\")\n",
    "            for i in range(3):\n",
    "                start_time = time.time()\n",
    "                insert_data(con, 'test'+f'_{k}', generate_data())\n",
    "                # print(f'insert time: {time.time()-start_time:.2f}s')\n",
    "            start_time = time.time()\n",
    "            con.raw_sql(\"COMMIT;\")\n",
    "            print(f'commit time: {time.time()-start_time:.2f}s')\n",
    "        start_time = time.time()\n",
    "        con.raw_sql(\"CHECKPOINT;\")\n",
    "        print(f'checkpoint time: {time.time()-start_time:.2f}s')\n",
    "    print(f'total time: {time.time()-total_start_time:.2f}s')\n",
    "    end_time = time.time()\n",
    "!ls -lh $output_path\n",
    "\n",
    "print(f'insert time: {time.time()-end_time:.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae404784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test reading from multiple dbs\n",
    "k=0\n",
    "with DB(f'{db_path}.0') as con:\n",
    "    con.attach(f'{db_path}.2', 'main1')\n",
    "    print(con.list_catalogs())\n",
    "    print(con.list_tables())\n",
    "    print(con.list_databases(catalog='main1'))\n",
    "    print(con.list_tables(database='main1.main'))\n",
    "    print(con.table('main1.main.test_0').execute().head(10))\n",
    "    # table = con.table('test')\n",
    "    # print(table.execute().groupby('label').agg({'label': 'count'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdd7da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "?con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d99e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test insert (with db utils)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import ibis\n",
    "import ibis.selectors as s\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import datetime\n",
    "from utils.db_utils import to_ibis_type, generate_schema, insert_data, generate_test_data, to_ibis_value, connect_db, analyze_data_size\n",
    "ibis.options.interactive = True\n",
    "output_path = 'dump/scene_graph_testing/objectnav-dino'\n",
    "db_path = f'{output_path}/test_insert.db'\n",
    "\n",
    "\n",
    "# save data as bytes\n",
    "os.remove(db_path) if os.path.exists(db_path) else None\n",
    "with DB(db_path) as con:\n",
    "    data = [{'test': pickle.dumps(np.random.rand(1024*1024*10))} for i in range(10)]\n",
    "    schema = generate_schema(data)\n",
    "    print(schema)\n",
    "    con.create_table('test', schema=schema, overwrite=True)\n",
    "    total_start_time = time.time()\n",
    "    con.raw_sql(\"BEGIN TRANSACTION;\")\n",
    "    insert_data(con, 'test', data)\n",
    "    con.raw_sql(\"COMMIT;\")\n",
    "    print(f'total time: {time.time()-total_start_time:.2f}s')\n",
    "\n",
    "# save data with pickle and time it\n",
    "with open(f'{output_path}/test.pkl', 'wb') as f:\n",
    "    start_time = time.time()\n",
    "    pickle.dump(data, f)\n",
    "    print(f'pickle dump time: {time.time()-start_time:.2f}s')\n",
    "\n",
    "# df = con.table('test').to_pandas()\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c1dfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.db_utils import generate_test_data, analyze_data_size\n",
    "analyze_data_size(generate_test_data(), threshold=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b85a9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ibis tutorial\n",
    "import ibis\n",
    "import ibis.selectors as s\n",
    "ibis.options.interactive = True\n",
    "output_path = '/dump/scene_graph_testing/objectnav-dino'\n",
    "con = ibis.connect(f\"duckdb:/{output_path}/penguins.db\")\n",
    "con.create_table(\n",
    "    \"penguins\", ibis.examples.penguins.fetch().to_pyarrow(), overwrite=True\n",
    ")\n",
    "penguins = con.table(\"penguins\")\n",
    "penguins.head(10)\n",
    "print('test1: ', penguins.filter((penguins.island == \"Torgersen\") & (penguins.species == \"Adelie\")))\n",
    "print('test2: ', penguins.select(\"species\", \"island\", \"year\"))\n",
    "\n",
    "print('test3: ', penguins.mutate(\n",
    "    bill_length_cm=penguins.bill_length_mm / 10,\n",
    "    continent=ibis.literal(\"Antarctica\")\n",
    ").select(\"bill_length_cm\").head(10))\n",
    "print('test4: ', penguins.select(\"island\", s.numeric()))\n",
    "print('test5: ', penguins.order_by(penguins.flipper_length_mm.desc()).select(\n",
    "    \"species\", \"island\", \"flipper_length_mm\"\n",
    ").head(10))\n",
    "print('test6: ', penguins.flipper_length_mm.mean())\n",
    "print('test7: ', penguins.group_by([\"species\", \"island\"]).aggregate(\n",
    "    [penguins.bill_length_mm.mean(), penguins.flipper_length_mm.max()]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc35684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test db: compare duckdb and numpy\n",
    "import numpy as np\n",
    "import ibis\n",
    "import ibis.selectors as s\n",
    "import os\n",
    "import time\n",
    "ibis.options.interactive = True\n",
    "output_path = 'dump/scene_graph_testing/objectnav-dino'\n",
    "\n",
    "# test1\n",
    "db_path = f'{output_path}/test1.ddb'\n",
    "os.remove(db_path) if os.path.exists(db_path) else None\n",
    "con = ibis.connect(f\"duckdb://{db_path}\")\n",
    "schema = ibis.schema(\n",
    "    {\n",
    "        'step': \"int\",\n",
    "        'successs': int,\n",
    "        'feat': \"array<float32>\",\n",
    "    }\n",
    ")\n",
    "con.create_table('test', schema=schema, overwrite=True)\n",
    "array_list = []\n",
    "for i in range(10):\n",
    "    test_array = np.ones(480*640*3).astype(np.float32)\n",
    "    array_list.append(test_array)\n",
    "time_start = time.time()\n",
    "con.insert('test', {'step':[800]*len(array_list), 'successs':[1]*len(array_list), 'feat': array_list})\n",
    "print(f'Time taken for duckdb: {time.time() - time_start} seconds')\n",
    "con.disconnect()\n",
    "start_time = time.time()\n",
    "np.save(f'./{output_path}/test1.npy', array_list)\n",
    "print(f'Time taken for numpy: {time.time() - start_time} seconds')\n",
    "time.sleep(1)\n",
    "\n",
    "# test2\n",
    "db_path = f'{output_path}/test2.ddb'\n",
    "os.remove(db_path) if os.path.exists(db_path) else None\n",
    "con = ibis.connect(f\"duckdb://{db_path}\")\n",
    "schema = ibis.schema(\n",
    "    {\n",
    "        'step': \"int\",\n",
    "        'successs': int,\n",
    "        'feat': \"binary\",\n",
    "    }\n",
    ")\n",
    "con.create_table('test', schema=schema, overwrite=True)\n",
    "array_list = []\n",
    "for i in range(10):\n",
    "    test_array = np.random.rand(480, 640, 3).astype(np.float32)\n",
    "    array_list.append(test_array.tobytes())\n",
    "time_start = time.time()\n",
    "con.insert('test', {'step':[800]*len(array_list), 'successs':[1]*len(array_list), 'feat': array_list})\n",
    "print(f'Time taken for duckdb: {time.time() - time_start} seconds')\n",
    "con.disconnect()\n",
    "start_time = time.time()\n",
    "np.save(f'./{output_path}/test2.npy', array_list)\n",
    "print(f'Time taken for numpy: {time.time() - start_time} seconds')\n",
    "! ls -lh {output_path}/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vln",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
